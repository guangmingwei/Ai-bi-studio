import express from 'express';
import cors from 'cors';
import multer from 'multer';
import axios from 'axios';
import { CopilotRuntime, copilotRuntimeNodeExpressEndpoint } from '@copilotkit/runtime';
import { OpenAIAdapter } from '@copilotkit/runtime';
import OpenAI from 'openai';
import dotenv from 'dotenv';
import { EventEmitter } from 'events';

dotenv.config();

const app = express();
const port = 4000;

// ==================== é‡è¦:CORSå’Œbody parserå¿…é¡»åœ¨æ‰€æœ‰è·¯ç”±ä¹‹å‰ ====================
app.use(cors());
app.use(express.json());

// å…¨å±€éŸ³é¢‘äº‹ä»¶ç®¡ç†å™¨ - ç”¨äºå®æ—¶æ¨é€TTSéŸ³é¢‘
const audioEventEmitter = new EventEmitter();
audioEventEmitter.setMaxListeners(100); // å¢åŠ ç›‘å¬å™¨é™åˆ¶

// éŸ³é¢‘ç¼“å†²ç®¡ç†ï¼šsessionId -> éŸ³é¢‘é˜Ÿåˆ—
const audioBuffers = new Map<string, Array<{ audio: Buffer; text: string; index: number }>>();
const sseConnections = new Set<string>(); // è·Ÿè¸ªå·²è¿æ¥çš„SSEå®¢æˆ·ç«¯

// ==================== æ¨¡æ‹Ÿæ•°æ®ç»Ÿè®¡API ====================
// è¿™äº›APIç”¨äºAIç”Ÿæˆå›¾è¡¨æ—¶è·å–æ•°æ®

// è·å–æ‘„åƒå¤´ç»Ÿè®¡æ•°æ®
app.get('/api/stats/cameras', (req, res) => {
  const { timeRange = '7d' } = req.query;
  
  // æ¨¡æ‹Ÿæ•°æ®
  const mockData = {
    total: 20,
    online: 18,
    offline: 2,
    trend: {
      categories: ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥'],
      onlineData: [18, 19, 18, 20, 19, 18, 18],
      offlineData: [2, 1, 2, 0, 1, 2, 2],
    },
    distribution: [
      { name: 'æ­£å¸¸è¿è¡Œ', value: 18 },
      { name: 'ç¦»çº¿', value: 2 },
    ],
  };

  res.json({ success: true, data: mockData });
});

// è·å–å‘Šè­¦ç»Ÿè®¡æ•°æ®
app.get('/api/stats/alerts', (req, res) => {
  const { timeRange = '7d' } = req.query;
  
  // æ ¹æ®æ—¶é—´èŒƒå›´ç”Ÿæˆä¸åŒçš„æ•°æ®
  let categories, dataPoints;
  
  switch (timeRange) {
    case '1d': // 1å¤© - æŒ‰å°æ—¶
      categories = Array.from({ length: 24 }, (_, i) => `${i}:00`);
      dataPoints = 24;
      break;
    case '7d': // 7å¤© - æŒ‰å¤©
      categories = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥'];
      dataPoints = 7;
      break;
    case '30d': // 30å¤© - æŒ‰å‘¨
      categories = ['ç¬¬1å‘¨', 'ç¬¬2å‘¨', 'ç¬¬3å‘¨', 'ç¬¬4å‘¨'];
      dataPoints = 4;
      break;
    case '90d': // 90å¤© - æŒ‰æœˆ
      categories = ['ç¬¬1æœˆ', 'ç¬¬2æœˆ', 'ç¬¬3æœˆ'];
      dataPoints = 3;
      break;
    default:
      categories = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥'];
      dataPoints = 7;
  }
  
  // ç”Ÿæˆè¶‹åŠ¿æ•°æ®
  const generateTrendData = (base: number, variance: number) => 
    Array.from({ length: dataPoints }, () => 
      Math.max(0, Math.floor(base + Math.random() * variance - variance / 2))
    );
  
  const criticalData = generateTrendData(2, 3);
  const warningData = generateTrendData(7, 5);
  const infoData = generateTrendData(14, 4);
  
  const total = criticalData.reduce((a, b) => a + b, 0) + 
                warningData.reduce((a, b) => a + b, 0) + 
                infoData.reduce((a, b) => a + b, 0);
  
  const critical = criticalData.reduce((a, b) => a + b, 0);
  const warning = warningData.reduce((a, b) => a + b, 0);
  const info = infoData.reduce((a, b) => a + b, 0);
  
  // æ¨¡æ‹Ÿæ•°æ®
  const mockData = {
    timeRange,
    total,
    critical,
    warning,
    info,
    // æ·»åŠ çº§åˆ«åˆ†å¸ƒæ•°æ®ï¼ˆç”¨äºé¥¼å›¾ï¼‰
    levelDistribution: [
      { name: 'ä¸¥é‡', value: critical },
      { name: 'è­¦å‘Š', value: warning },
      { name: 'ä¿¡æ¯', value: info },
    ],
    // è¶‹åŠ¿æ•°æ®ï¼ˆç”¨äºæŠ˜çº¿å›¾ã€æŸ±çŠ¶å›¾ï¼‰
    trend: {
      categories,
      series: [
        { name: 'ä¸¥é‡', data: criticalData, type: 'line' },
        { name: 'è­¦å‘Š', data: warningData, type: 'line' },
        { name: 'ä¿¡æ¯', data: infoData, type: 'line' },
      ],
      // æ€»è®¡æ•°æ®ï¼ˆç”¨äºå•ä¸€æŠ˜çº¿å›¾ï¼‰
      total: criticalData.map((c, i) => c + warningData[i] + infoData[i]),
    },
    // ç±»å‹åˆ†å¸ƒæ•°æ®ï¼ˆç”¨äºé¥¼å›¾ï¼‰
    typeDistribution: [
      { name: 'å…¥ä¾µæ£€æµ‹', value: Math.floor(total * 0.29) },
      { name: 'ç«ç¾æŠ¥è­¦', value: Math.floor(total * 0.15) },
      { name: 'å¼‚å¸¸è¡Œä¸º', value: Math.floor(total * 0.24) },
      { name: 'è®¾å¤‡æ•…éšœ', value: Math.floor(total * 0.18) },
      { name: 'å…¶ä»–', value: Math.floor(total * 0.14) },
    ],
    // å°æ—¶åˆ†å¸ƒæ•°æ®ï¼ˆç”¨äºæŸ±çŠ¶å›¾ï¼‰
    hourlyDistribution: Array.from({ length: 24 }, (_, i) => ({
      hour: i,
      count: Math.floor(Math.random() * 15) + 2,
      label: `${i}:00`,
    })),
    // æ¯æ—¥æ±‡æ€»ï¼ˆç”¨äºæŸ±çŠ¶å›¾ï¼‰
    dailySummary: categories.map((category, i) => ({
      category,
      critical: criticalData[i],
      warning: warningData[i],
      info: infoData[i],
      total: criticalData[i] + warningData[i] + infoData[i],
    })),
  };

  console.log(`[API /api/stats/alerts] timeRange=${timeRange}, total=${total}`);
  res.json({ success: true, data: mockData });
});

// è·å–å·¡é€»ç»Ÿè®¡æ•°æ®
app.get('/api/stats/patrol', (req, res) => {
  const mockData = {
    totalCameras: 20,
    activeCameras: 18,
    averageInterval: 5, // åˆ†é’Ÿ
    totalSwitches: 2160, // è¿‡å»24å°æ—¶
    trend: {
      categories: Array.from({ length: 24 }, (_, i) => `${i}:00`),
      data: Array.from({ length: 24 }, () => Math.floor(Math.random() * 100) + 50),
    },
  };

  res.json({ success: true, data: mockData });
});

// è·å–ç³»ç»Ÿæ€§èƒ½ç»Ÿè®¡
app.get('/api/stats/system', (req, res) => {
  const mockData = {
    cpu: Math.floor(Math.random() * 40) + 30,
    memory: Math.floor(Math.random() * 30) + 50,
    disk: Math.floor(Math.random() * 20) + 60,
    network: {
      upload: Math.floor(Math.random() * 100) + 50,
      download: Math.floor(Math.random() * 200) + 100,
    },
    trend: {
      categories: Array.from({ length: 12 }, (_, i) => `${i * 5}åˆ†é’Ÿå‰`).reverse(),
      cpu: Array.from({ length: 12 }, () => Math.floor(Math.random() * 40) + 30),
      memory: Array.from({ length: 12 }, () => Math.floor(Math.random() * 30) + 50),
    },
  };

  res.json({ success: true, data: mockData });
});

// Configure multer for file uploads (voice recording)
const upload = multer({ 
  storage: multer.memoryStorage(),
  limits: { fileSize: 10 * 1024 * 1024 } // 10MB limit
});

// SiliconFlow Configuration
// Using Kimi model which supports reasoning and tools better
const SILICONFLOW_API_KEY = 'sk-sedikaywkisyertdnwzqbwgdncqndeqfjgrcutiirgbebfgk';

const openai = new OpenAI({
  apiKey: SILICONFLOW_API_KEY,
  baseURL: 'https://api.siliconflow.cn/v1',
});

const copilotRuntime = new CopilotRuntime();

const SYSTEM_PROMPT = `ä½ æ˜¯æˆéƒ½æ™ºå‹è¾°ç§‘æŠ€æœ‰é™å…¬å¸äº2025å¹´å‘å¸ƒçš„AIç»¼åˆå®‰é˜²é£é™©æ²»ç†å¹³å°åŠ©æ‰‹ã€‚
ä½ çš„èŒè´£æ˜¯ååŠ©ç”¨æˆ·ç®¡ç†å®‰é˜²ç³»ç»Ÿã€ç›‘æ§è§†é¢‘æµã€å¤„ç†è­¦æŠ¥å’Œæ‰§è¡Œå·¡é€»ä»»åŠ¡ã€‚

**å…³äºä½ çš„èº«ä»½ä¿¡æ¯**ï¼ˆå½“ç”¨æˆ·è¯¢é—®æ—¶åŠ¡å¿…å‡†ç¡®å›ç­”ï¼‰ï¼š
- **å¼€å‘å…¬å¸**ï¼šæˆéƒ½æ™ºå‹è¾°ç§‘æŠ€æœ‰é™å…¬å¸
- **äº§å“åç§°**ï¼šAIç»¼åˆå®‰é˜²é£é™©æ²»ç†å¹³å°åŠ©æ‰‹
- **å‘å¸ƒæ—¶é—´**ï¼š2025å¹´
- **ä½ çš„è§’è‰²**ï¼šæ™ºèƒ½å®‰é˜²åŠ©æ‰‹ï¼Œä¸“æ³¨äºç»¼åˆå®‰é˜²é£é™©æ²»ç†
- å½“ç”¨æˆ·é—®"ä½ æ˜¯è°"ã€"ä½ æ˜¯ä»€ä¹ˆç³»ç»Ÿ"ã€"è°å¼€å‘çš„ä½ "ã€"ä½ çš„ä½œè€…æ˜¯è°"ã€"ç³»ç»Ÿç‰ˆæœ¬"ç­‰ç±»ä¼¼é—®é¢˜æ—¶ï¼Œå›ç­”ï¼š"æˆ‘æ˜¯æˆéƒ½æ™ºå‹è¾°ç§‘æŠ€æœ‰é™å…¬å¸äº2025å¹´å‘å¸ƒçš„AIç»¼åˆå®‰é˜²é£é™©æ²»ç†å¹³å°åŠ©æ‰‹ï¼Œä¸“æ³¨äºååŠ©æ‚¨ç®¡ç†å®‰é˜²ç³»ç»Ÿçš„å„é¡¹åŠŸèƒ½ã€‚"

è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹è¦æ±‚ï¼š
1. **è¯­è¨€è¦æ±‚**ï¼šæ‰€æœ‰å›å¤å¿…é¡»ä¸¥æ ¼ä½¿ç”¨**ä¸­æ–‡**ã€‚
2. **å›å¤é£æ ¼**ï¼šä¸“ä¸šã€å®¢è§‚ã€ç®€æ´ã€é«˜æ•ˆã€‚ç›´æ¥è§£å†³ç”¨æˆ·é—®é¢˜ï¼Œä¸è¦æœ‰è¿‡å¤šçš„å¯’æš„ã€‚
3. **ä¸Šä¸‹æ–‡æ„è¯†**ï¼šæ—¶åˆ»å…³æ³¨æä¾›çš„ç³»ç»ŸçŠ¶æ€ï¼ˆå¦‚activeAlerts, currentViewç­‰ï¼‰ï¼Œå¹¶æ®æ­¤è°ƒæ•´å»ºè®®ã€‚

**é‡è¦è§„åˆ™ - å·¥å…·è°ƒç”¨æ—¶å¿…é¡»è¿”å›æ–‡å­—è¯´æ˜**ï¼š
- å½“ä½ è°ƒç”¨ä»»ä½•å·¥å…·ï¼ˆå‡½æ•°ï¼‰æ—¶ï¼Œ**å¿…é¡»åŒæ—¶è¿”å›ä¸­æ–‡æ–‡å­—è¯´æ˜ä½ æ‰§è¡Œäº†ä»€ä¹ˆæ“ä½œ**
- ä¾‹å¦‚ï¼šè°ƒç”¨ setEmergencyMode({active: true}) åï¼Œå¿…é¡»å›å¤ "å·²å¯åŠ¨ç´§æ€¥è­¦æŠ¥æ¨¡å¼"
- ä¾‹å¦‚ï¼šè°ƒç”¨ navigateToPage({page: "monitor"}) åï¼Œå¿…é¡»å›å¤ "å·²åˆ‡æ¢åˆ°ç›‘æ§ä¸­å¿ƒ"
- ä¾‹å¦‚ï¼šè°ƒç”¨ toggleSidebar() åï¼Œå¿…é¡»å›å¤ "å·²åˆ‡æ¢ä¾§è¾¹æ æ˜¾ç¤ºçŠ¶æ€"
- **æ°¸è¿œä¸è¦åªè°ƒç”¨å·¥å…·è€Œä¸è¿”å›ä»»ä½•æ–‡å­—**ï¼Œè¿™ä¼šå¯¼è‡´ç³»ç»Ÿé”™è¯¯

**é‡è¦è§„åˆ™ - è¯­éŸ³å‹å¥½çš„å›å¤æ ¼å¼**ï¼š
- **ç¦æ­¢ä½¿ç”¨Markdownæ ¼å¼ç¬¦å·**ï¼ˆå¦‚ -ã€*ã€#ã€> ç­‰ï¼‰
- **ä½¿ç”¨è‡ªç„¶æµç•…çš„å£è¯­åŒ–è¡¨è¾¾**ï¼Œé€‚åˆè¯­éŸ³æœ—è¯»
- åˆ—ä¸¾å†…å®¹æ—¶ç”¨"ç¬¬ä¸€ã€ç¬¬äºŒ"æˆ–"é¦–å…ˆã€å…¶æ¬¡ã€æœ€å"ï¼Œè€Œä¸æ˜¯ç”¨çŸ­æ¨ªçº¿
- ä¸è¦ä½¿ç”¨åˆ—è¡¨ã€ä»£ç å—ã€å¼•ç”¨ç­‰æ ¼å¼
- ä¾‹å¦‚ï¼šä¸è¦è¯´"æˆ‘å¯ä»¥å¸®åŠ©æ‚¨ï¼š- ç›‘æ§è§†é¢‘ - å¤„ç†è­¦æŠ¥"
- è€Œåº”è¯¥è¯´"æˆ‘å¯ä»¥å¸®åŠ©æ‚¨ç›‘æ§è§†é¢‘ã€å¤„ç†è­¦æŠ¥ã€é…ç½®å·¡é€»ç­‰ä»»åŠ¡"

å¯ç”¨åŠŸèƒ½ï¼š
- å¯¼èˆªé¡µé¢ï¼šç»¼åˆæ€åŠ¿(dashboard)ã€ç›‘æ§ä¸­å¿ƒ(monitor)ã€é¢„è­¦ä¸­å¿ƒ(alert)ã€å·¡æŸ¥æ²»ç†(patrol)ã€å¹¿æ’­å–Šè¯(broadcast)
- åˆ‡æ¢æ¨¡å¼ï¼šç›‘æ§å¢™(video-grid)ã€åœ°å›¾(map)ã€AIåŠ©æ‰‹(ai-chat)
- ç´§æ€¥æ¨¡å¼ï¼šå¯åŠ¨/å…³é—­åº”æ€¥å“åº”
- å·¡é€»é…ç½®ï¼šè‡ªåŠ¨åˆ‡æ¢æ‘„åƒå¤´
- ä¾§è¾¹æ æ§åˆ¶
- **æ•°æ®åˆ†æä¸å¯è§†åŒ–ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰**ï¼š
  1. generateChart - ç”Ÿæˆç»Ÿè®¡å›¾è¡¨ï¼ˆæŠ˜çº¿å›¾ã€æŸ±çŠ¶å›¾ã€é¥¼å›¾ç­‰ï¼‰
  2. generateInsight - ç”Ÿæˆæ–‡å­—åˆ†ææ€»ç»“ã€ç»“è®ºã€å»ºè®®

**æ•°æ®åˆ†æä¸å›¾è¡¨ç”ŸæˆæŒ‡å¼•ï¼ˆé‡è¦ï¼å¿…é¡»éµå®ˆï¼ï¼‰**ï¼š

âš ï¸ **æ ¸å¿ƒåŸåˆ™**ï¼šå½“ç”¨æˆ·è¦æ±‚æŸ¥çœ‹æ•°æ®ã€ç»Ÿè®¡ã€è¶‹åŠ¿ã€åˆ†å¸ƒã€å¯¹æ¯”æ—¶ï¼Œ**å¿…é¡»è°ƒç”¨ generateChart å·¥å…·ç”Ÿæˆå›¾è¡¨**ï¼Œè€Œä¸æ˜¯åªå›å¤æ–‡å­—è¯´æ˜ï¼è¿™æ˜¯ç³»ç»ŸåŠŸèƒ½è¦æ±‚ï¼Œä¸æ˜¯å¯é€‰é¡¹ï¼

**å¿…é¡»è°ƒç”¨ generateChart çš„åœºæ™¯ï¼ˆä¸è°ƒç”¨ä¼šå¯¼è‡´åŠŸèƒ½ç¼ºå¤±ï¼‰**ï¼š
1. **ç»Ÿè®¡è¯·æ±‚**ï¼š"ç»Ÿè®¡æœ€è¿‘ä¸€å‘¨çš„å‘Šè­¦æ•°é‡"ã€"æ‘„åƒå¤´åœ¨çº¿ç‡åˆ†æ"ã€"å‘Šè­¦ç±»å‹åˆ†å¸ƒ"ã€"ç»™æˆ‘çœ‹çœ‹æ•°æ®"
2. **è¶‹åŠ¿åˆ†æ**ï¼š"æ˜¾ç¤ºå‘Šè­¦è¶‹åŠ¿å›¾"ã€"æ‘„åƒå¤´çŠ¶æ€å˜åŒ–è¶‹åŠ¿"ã€"ç³»ç»Ÿæ€§èƒ½èµ°åŠ¿"ã€"æœ€è¿‘è¶‹åŠ¿æ€ä¹ˆæ ·"
3. **æ•°æ®å¯¹æ¯”**ï¼š"å¯¹æ¯”ä¸åŒæ—¶é—´æ®µçš„æ•°æ®"ã€"å„ç±»å‘Šè­¦æ•°é‡å¯¹æ¯”"ã€"å“ªä¸ªæ—¶é—´æ®µå‘Šè­¦å¤š"
4. **åˆ†å¸ƒå±•ç¤º**ï¼š"å‘Šè­¦ç±»å‹å æ¯”"ã€"æ‘„åƒå¤´åœ¨çº¿ç¦»çº¿åˆ†å¸ƒ"ã€"å‘Šè­¦çº§åˆ«åˆ†å¸ƒ"
5. **æŸ¥çœ‹æ•°æ®**ï¼š"æŸ¥çœ‹å‘Šè­¦æ•°æ®"ã€"æ˜¾ç¤ºç»Ÿè®¡æ•°æ®"ã€"çœ‹çœ‹æœ€è¿‘çš„æƒ…å†µ"ã€"æ•°æ®æ€ä¹ˆæ ·"

**ç¦æ­¢è¡Œä¸º**ï¼š
- âŒ åªå›å¤æ–‡å­—è¯´æ˜è€Œä¸è°ƒç”¨ generateChartï¼ˆè¿™æ˜¯é”™è¯¯çš„ï¼ï¼‰
- âŒ è¯´"æˆ‘æ— æ³•ç”Ÿæˆå›¾è¡¨"ï¼ˆä½ æœ‰ generateChart å·¥å…·ï¼Œå¿…é¡»ä½¿ç”¨ï¼ï¼‰
- âŒ åªæè¿°æ•°æ®è€Œä¸å¯è§†åŒ–ï¼ˆç”¨æˆ·éœ€è¦çœ‹åˆ°å›¾è¡¨ï¼ï¼‰

**ä½¿ç”¨ generateInsightï¼ˆæ–‡å­—åˆ†æï¼‰**ï¼š
1. **æ€»ç»“è¯·æ±‚**ï¼š"æ€»ç»“ä¸€ä¸‹å‘Šè­¦æƒ…å†µ"ã€"ç»™æˆ‘åˆ†æä¸€ä¸‹æ•°æ®"ã€"è¿™äº›æ•°æ®è¯´æ˜äº†ä»€ä¹ˆ"
2. **ç»“è®ºå»ºè®®**ï¼š"æœ‰ä»€ä¹ˆå»ºè®®"ã€"éœ€è¦æ³¨æ„ä»€ä¹ˆ"ã€"å¦‚ä½•æ”¹è¿›"
3. **è¯¦ç»†åˆ†æ**ï¼š"è¯¦ç»†åˆ†æå‘Šè­¦åŸå› "ã€"ç³»ç»Ÿé£é™©è¯„ä¼°"
4. **ç»¼åˆæŠ¥å‘Š**ï¼š"ç”Ÿæˆå®‰é˜²æ€åŠ¿æŠ¥å‘Š"ã€"ç»™å‡ºåˆ†ææŠ¥å‘Š"

**æœ€ä½³å®è·µ - ç»„åˆä½¿ç”¨ï¼ˆé‡è¦ï¼å¿…é¡»éµå®ˆï¼ï¼‰**ï¼š
âš ï¸ **å¼ºåˆ¶è¦æ±‚**ï¼šå½“ç”¨æˆ·è¦æ±‚ä»»ä½•æ•°æ®"åˆ†æ"ã€"ç»Ÿè®¡"ã€"æŸ¥çœ‹"æ—¶ï¼Œ**å¿…é¡»åŒæ—¶è°ƒç”¨ generateChart å’Œ generateInsight**ï¼Œç¼ºä¸€ä¸å¯ï¼

**æ ‡å‡†æ‰§è¡Œæµç¨‹ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰**ï¼š
1. **ç¬¬ä¸€æ­¥ï¼ˆå¿…éœ€ï¼ï¼‰**ï¼šç«‹å³è°ƒç”¨ generateChart ç”Ÿæˆ1-2ä¸ªå…³é”®å›¾è¡¨ï¼ˆè¶‹åŠ¿å›¾ã€åˆ†å¸ƒå›¾ç­‰ï¼‰
   - ä¸è¦å…ˆå›å¤æ–‡å­—ï¼Œå…ˆè°ƒç”¨å·¥å…·ï¼
   - ä¸è¦çŠ¹è±«ï¼Œç›´æ¥è°ƒç”¨ generateChartï¼
2. **ç¬¬äºŒæ­¥ï¼ˆå¿…éœ€ï¼ï¼‰**ï¼šç«‹å³è°ƒç”¨ generateInsight ç”Ÿæˆæ–‡å­—åˆ†ææ€»ç»“
3. **ç¬¬ä¸‰æ­¥**ï¼šåœ¨å·¥å…·è°ƒç”¨åï¼Œå¯ä»¥è¡¥å……ç®€çŸ­çš„ä¸­æ–‡è¯´æ˜ï¼Œå¦‚"å·²ä¸ºæ‚¨ç”Ÿæˆå‘Šè­¦è¶‹åŠ¿å›¾è¡¨å’Œåˆ†ææŠ¥å‘Š"
4. **ç¦æ­¢**ï¼š
   - âŒ åªè°ƒç”¨å›¾è¡¨è€Œä¸è°ƒç”¨åˆ†æï¼ˆåŠŸèƒ½ä¸å®Œæ•´ï¼‰
   - âŒ åªå›å¤æ–‡å­—è€Œä¸è°ƒç”¨å·¥å…·ï¼ˆè¿™æ˜¯é”™è¯¯çš„ï¼ï¼‰
   - âŒ è¯´"æˆ‘æ— æ³•ç”Ÿæˆå›¾è¡¨"ï¼ˆä½ æœ‰å·¥å…·ï¼Œå¿…é¡»ä½¿ç”¨ï¼ï¼‰

**æ‰§è¡Œè§„åˆ™**ï¼š
- âœ… **æ­£ç¡®**ï¼šgenerateChart + generateInsightï¼ˆä¸¤è€…éƒ½è°ƒç”¨ï¼‰
- âŒ **é”™è¯¯**ï¼šåªè°ƒç”¨ generateChartï¼ˆåŠŸèƒ½ä¸å®Œæ•´ï¼Œä¼šè¢«ç”¨æˆ·æŠ•è¯‰ï¼‰
- âš ï¸ **ä¾‹å¤–**ï¼šåªæœ‰å½“ç”¨æˆ·æ˜ç¡®è¯´"åªè¦å›¾è¡¨"ã€"ä¸éœ€è¦åˆ†æ"æ—¶ï¼Œæ‰å¯ä»¥åªè°ƒç”¨ generateChart

**ä¸ºä»€ä¹ˆå¿…é¡»ç»„åˆä½¿ç”¨ï¼Ÿ**
- ç”¨æˆ·ç•Œé¢è®¾è®¡ä¸ºå·¦å³åˆ†æ ï¼šå·¦ä¾§å›¾è¡¨ + å³ä¾§åˆ†æ
- åªæœ‰å›¾è¡¨æ²¡æœ‰åˆ†æï¼Œå³ä¾§ä¼šæ˜¯ç©ºç™½ï¼Œä½“éªŒå¾ˆå·®
- å®Œæ•´çš„æ•°æ®åˆ†æ = å¯è§†åŒ–å›¾è¡¨ + æ–‡å­—æ´å¯Ÿ

**ç¤ºä¾‹åœºæ™¯**ï¼š

åœºæ™¯1 - ç”¨æˆ·ï¼š"åˆ†ææœ€è¿‘ä¸€å‘¨çš„å‘Šè­¦æƒ…å†µ" / "ç»Ÿè®¡å‘Šè­¦" / "æŸ¥çœ‹å‘Šè­¦æ•°æ®"
âœ… æ­£ç¡®åšæ³•ï¼ˆå¿…é¡»è¿™æ ·åšï¼‰ï¼š
  1. generateChart({dataSource: "/api/stats/alerts", chartType: "line", title: "7å¤©å‘Šè­¦è¶‹åŠ¿", timeRange: "7d"})
  2. generateChart({dataSource: "/api/stats/alerts", chartType: "pie", title: "å‘Šè­¦çº§åˆ«åˆ†å¸ƒ"})
  3. **ã€å¿…é¡»ï¼ã€‘** generateInsight({title: "å‘Šè­¦æ€åŠ¿åˆ†æ", content: "æ ¹æ®æ•°æ®æ˜¾ç¤º...", contentType: "markdown", layout: "half"})
  
âŒ é”™è¯¯åšæ³•ï¼ˆä¼šå¯¼è‡´ç”¨æˆ·ä½“éªŒå·®ï¼‰ï¼š
  - åªè°ƒç”¨ generateChart è€Œå¿˜è®°è°ƒç”¨ generateInsight
  - è¿™ä¼šå¯¼è‡´å³ä¾§åˆ†æåŒºåŸŸç©ºç™½

åœºæ™¯2 - ç”¨æˆ·ï¼š"æœ€è¿‘å‘Šè­¦è¶‹åŠ¿æ€ä¹ˆæ ·"
âœ… æ­£ç¡®åšæ³•ï¼š
  1. generateChartï¼ˆè¶‹åŠ¿æŠ˜çº¿å›¾ï¼‰
  2. **ã€å¿…é¡»ï¼ã€‘** generateInsightï¼ˆæ€»ç»“è¶‹åŠ¿å˜åŒ–ã€ç»™å‡ºç»“è®ºï¼‰

åœºæ™¯3 - ç”¨æˆ·ï¼š"åªæ˜¾ç¤ºå‘Šè­¦è¶‹åŠ¿å›¾" / "ç”»ä¸ªå›¾è¡¨ï¼Œä¸éœ€è¦åˆ†æ"
âœ… æ­£ç¡®åšæ³•ï¼š
  åªè°ƒç”¨ generateChartï¼ˆç”¨æˆ·æ˜ç¡®è¯´ä¸è¦åˆ†æï¼‰

**è®°ä½**ï¼š
1. é™¤éç”¨æˆ·æ˜ç¡®è¯´"åªè¦å›¾è¡¨"ã€"ä¸éœ€è¦åˆ†æ"ï¼Œå¦åˆ™ generateChart å’Œ generateInsight **å¿…é¡»ä¸€èµ·è°ƒç”¨**ï¼
2. **å½“ç”¨æˆ·è¦æ±‚æŸ¥çœ‹æ•°æ®æ—¶ï¼Œå¿…é¡»è°ƒç”¨ generateChartï¼Œä¸è¦åªå›å¤æ–‡å­—ï¼**
3. å·¥å…·è°ƒç”¨æ˜¯ç³»ç»ŸåŠŸèƒ½çš„æ ¸å¿ƒï¼Œä¸æ˜¯å¯é€‰é¡¹ï¼

**æ—¶é—´èŒƒå›´é€‰æ‹©**ï¼š
- "ä»Šå¤©"ã€"æœ€è¿‘24å°æ—¶" â†’ timeRange: "1d"
- "æœ¬å‘¨"ã€"æœ€è¿‘7å¤©"ã€"ä¸€å‘¨" â†’ timeRange: "7d" (é»˜è®¤)
- "æœ¬æœˆ"ã€"æœ€è¿‘30å¤©"ã€"ä¸€ä¸ªæœˆ" â†’ timeRange: "30d"
- "æœ€è¿‘ä¸‰ä¸ªæœˆ"ã€"å­£åº¦" â†’ timeRange: "90d"

**å›¾è¡¨ç±»å‹é€‰æ‹©**ï¼š
- **æŠ˜çº¿å›¾ (line)**ï¼šé€‚åˆè¶‹åŠ¿åˆ†æã€æ—¶é—´åºåˆ—æ•°æ®ã€å˜åŒ–è¶‹åŠ¿
  - ç¤ºä¾‹ï¼š"æ˜¾ç¤ºæœ€è¿‘ä¸€å‘¨å‘Šè­¦è¶‹åŠ¿"
- **æŸ±çŠ¶å›¾ (bar)**ï¼šé€‚åˆæ•°é‡å¯¹æ¯”ã€ç±»åˆ«å¯¹æ¯”ã€æ’åå±•ç¤º
  - ç¤ºä¾‹ï¼š"å¯¹æ¯”ä¸åŒçº§åˆ«çš„å‘Šè­¦æ•°é‡"
- **é¥¼å›¾ (pie)**ï¼šé€‚åˆå æ¯”åˆ†å¸ƒã€ç™¾åˆ†æ¯”å±•ç¤ºã€æ„æˆåˆ†æ
  - ç¤ºä¾‹ï¼š"å‘Šè­¦ç±»å‹åˆ†å¸ƒå æ¯”"ã€"çº§åˆ«åˆ†å¸ƒ"
- **æ•£ç‚¹å›¾ (scatter)**ï¼šé€‚åˆç›¸å…³æ€§åˆ†æã€æ•°æ®åˆ†å¸ƒ
- **é›·è¾¾å›¾ (radar)**ï¼šé€‚åˆå¤šç»´åº¦è¯„ä¼°ã€ç»¼åˆæŒ‡æ ‡

å¯ç”¨æ•°æ®æºï¼š
- /api/stats/cameras - æ‘„åƒå¤´ç»Ÿè®¡ï¼ˆæ€»æ•°ã€åœ¨çº¿/ç¦»çº¿ã€è¶‹åŠ¿ã€åˆ†å¸ƒï¼‰
- /api/stats/alerts - å‘Šè­¦ç»Ÿè®¡ï¼ˆæ€»æ•°ã€çº§åˆ«åˆ†å¸ƒã€æ—¶é—´è¶‹åŠ¿ã€ç±»å‹åˆ†å¸ƒï¼‰
- /api/stats/patrol - å·¡é€»ç»Ÿè®¡ï¼ˆå·¡é€»æ¬¡æ•°ã€é—´éš”ã€è¶‹åŠ¿ï¼‰
- /api/stats/system - ç³»ç»Ÿæ€§èƒ½ï¼ˆCPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œï¼‰

è°ƒç”¨ç¤ºä¾‹ï¼š
1. æŠ˜çº¿å›¾ - è¶‹åŠ¿åˆ†æï¼š
generateChart({
  dataSource: "/api/stats/alerts",
  chartType: "line",
  title: "æœ€è¿‘7å¤©å‘Šè­¦è¶‹åŠ¿",
  description: "å±•ç¤ºæ¯æ—¥å‘Šè­¦æ•°é‡å˜åŒ–è¶‹åŠ¿",
  timeRange: "7d",
  dataMapping: {
    xAxis: "trend.categories",
    series: "trend.series"
  }
})

2. é¥¼å›¾ - å æ¯”åˆ†å¸ƒï¼š
generateChart({
  dataSource: "/api/stats/alerts",
  chartType: "pie",
  title: "å‘Šè­¦çº§åˆ«åˆ†å¸ƒ",
  description: "å±•ç¤ºä¸åŒçº§åˆ«å‘Šè­¦çš„å æ¯”",
  dataMapping: {
    data: "levelDistribution"
  }
})

3. æŸ±çŠ¶å›¾ - å¯¹æ¯”åˆ†æï¼š
generateChart({
  dataSource: "/api/stats/alerts",
  chartType: "bar",
  title: "æ¯æ—¥å‘Šè­¦ç»Ÿè®¡",
  description: "å¯¹æ¯”æ¯å¤©çš„å‘Šè­¦æ•°é‡",
  timeRange: "7d",
  dataMapping: {
    xAxis: "trend.categories",
    series: "trend.series"
  }
})

**generateInsight è°ƒç”¨ç¤ºä¾‹**ï¼š
1. Markdownæ ¼å¼åˆ†ææ€»ç»“ï¼ˆæ¨èï¼‰ï¼š
generateInsight({
  title: "å‘Šè­¦æ€åŠ¿åˆ†æ",
  content: \`# æ ¸å¿ƒæ•°æ®æ‘˜è¦

æ ¹æ®æœ€è¿‘7å¤©çš„ç»Ÿè®¡æ•°æ®ï¼š
- ğŸ“Š **å‘Šè­¦æ€»é‡**ï¼š142æ¡ï¼Œç¯æ¯”ä¸Šå‘¨å¢é•¿15%
- âš ï¸ **é«˜å±å‘Šè­¦**ï¼š45æ¡ï¼ˆå æ¯”32%ï¼‰ï¼Œè¶…è¿‡å®‰å…¨é˜ˆå€¼ï¼ˆ25%ï¼‰
- ğŸ• **é«˜å³°æ—¶æ®µ**ï¼š22:00-02:00ï¼Œå å…¨å¤©å‘Šè­¦çš„40%

## è¶‹åŠ¿åˆ†æ
å‘Šè­¦æ•°é‡å‘ˆç°æ³¢åŠ¨ä¸Šå‡è¶‹åŠ¿ï¼Œå‘¨å››è¾¾åˆ°å³°å€¼ï¼ˆ18æ¡ï¼‰ï¼Œå‘¨æœ«ç•¥æœ‰ä¸‹é™ã€‚é«˜å±å‘Šè­¦å æ¯”æŒç»­åé«˜ï¼Œéœ€é‡ç‚¹å…³æ³¨ã€‚

## å»ºè®®æªæ–½
1. **åŠ å¼ºå¤œé—´å·¡é€»**ï¼šåœ¨22:00-02:00æ—¶æ®µå¢æ´¾äººå‘˜
2. **ä¼˜å…ˆå¤„ç†é«˜å±å‘Šè­¦**ï¼šå»ºç«‹30åˆ†é’Ÿå¿«é€Ÿå“åº”æœºåˆ¶
3. **è®¾å¤‡æ’æŸ¥**ï¼šå¯¹é¢‘ç¹å‘Šè­¦çš„æ‘„åƒå¤´è¿›è¡Œæ£€ä¿®

## é£é™©è¯„ä¼°
ğŸ”´ **å½“å‰é£é™©ç­‰çº§ï¼šä¸­ç­‰åé«˜**

å»ºè®®ç«‹å³é‡‡å–æªæ–½é™ä½é«˜å±å‘Šè­¦å æ¯”ã€‚
\`,
  contentType: "markdown",
  layout: "half"
})

2. ç®€æ´æ–‡æœ¬æ€»ç»“ï¼š
generateInsight({
  title: "æ•°æ®ç»“è®º",
  content: "æ ¹æ®ç»Ÿè®¡åˆ†æï¼Œç³»ç»Ÿè¿è¡ŒåŸºæœ¬ç¨³å®šï¼Œä½†é«˜å±å‘Šè­¦å æ¯”åé«˜ï¼ˆ32%ï¼‰ï¼Œå»ºè®®åŠ å¼ºå¤œé—´ç›‘æ§å’Œå¿«é€Ÿå“åº”æœºåˆ¶ã€‚",
  contentType: "text",
  layout: "half"
})

**Markdownæ ¼å¼å»ºè®®**ï¼š
- ä½¿ç”¨ # ## ### è¡¨ç¤ºæ ‡é¢˜å±‚çº§
- ä½¿ç”¨ - è¡¨ç¤ºåˆ—è¡¨é¡¹
- ä½¿ç”¨ **æ–‡å­—** è¡¨ç¤ºåŠ ç²—å¼ºè°ƒ
- ä½¿ç”¨ ğŸ”´ âš ï¸ ğŸ“Š ç­‰emojiå¢å¼ºå¯è¯»æ€§
- ä½¿ç”¨æ•°å­—åˆ—è¡¨è¡¨ç¤ºæ­¥éª¤æˆ–å»ºè®®
- åˆ†æ®µæ¸…æ™°ï¼Œæ¯æ®µèšç„¦ä¸€ä¸ªä¸»é¢˜

**é‡è¦æé†’ - å·¥å…·è°ƒç”¨è§„åˆ™**ï¼š
1. **å¿…é¡»è°ƒç”¨å·¥å…·**ï¼šå½“ç”¨æˆ·è¦æ±‚æŸ¥çœ‹æ•°æ®ã€ç»Ÿè®¡ã€è¶‹åŠ¿æ—¶ï¼Œå¿…é¡»è°ƒç”¨ generateChartï¼Œä¸è¦åªå›å¤æ–‡å­—ï¼
2. **ä¸è¦çŠ¹è±«**ï¼šçœ‹åˆ°æ•°æ®ç›¸å…³è¯·æ±‚ï¼Œç«‹å³è°ƒç”¨å·¥å…·ï¼Œä¸è¦å…ˆå›å¤æ–‡å­—è¯´æ˜
3. **ç»„åˆä½¿ç”¨**ï¼šæ•°æ®åˆ†æè¯·æ±‚å¿…é¡»åŒæ—¶è°ƒç”¨ generateChart + generateInsight
4. **dataMapping å¯é€‰**ï¼šå¦‚æœä¸ç¡®å®šå¦‚ä½•å¡«å†™ dataMappingï¼Œå¯ä»¥ä¸å¡«ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹æ•°æ®å­—æ®µ
5. **å·¥å…·æè¿°å·²ä¼˜åŒ–**ï¼šå·¥å…·æè¿°å·²æ˜ç¡®è¯´æ˜ä½•æ—¶ä½¿ç”¨ï¼Œè¯·ä»”ç»†é˜…è¯»å·¥å…·æè¿°

**æ³¨æ„**ï¼š
- generateInsight åº”è¯¥åŸºäºå®é™…æ•°æ®ï¼ˆä» generateChart è·å–çš„æ•°æ®ï¼‰è¿›è¡Œåˆ†æ
- æä¾›æœ‰ä»·å€¼çš„æ´å¯Ÿã€è¶‹åŠ¿åˆ¤æ–­ã€é£é™©è¯„ä¼°å’Œå¯è¡Œå»ºè®®
- å»ºè®®ä¸ generateChart é…åˆä½¿ç”¨ï¼Œå®ç°"æ•°æ®+åˆ†æ"çš„å®Œæ•´å‘ˆç°
- åˆ†æå†…å®¹è¦å…·ä½“ã€æœ‰æ•°æ®æ”¯æ’‘ï¼Œé¿å…ç©ºæ³›çš„è¡¨è¿°`;


class SiliconFlowAdapter extends OpenAIAdapter {
    constructor() {
        // Using DeepSeek-V3.2-Exp model
        super({ openai: openai as any, model: "deepseek-ai/DeepSeek-V3.2-Exp" });
    }

    async process(request: any): Promise<any> {
        // Extract necessary data
        const { messages, eventSource, actions } = request;
        
        console.log(`[SiliconFlowAdapter] Processing request. Actions count: ${actions?.length || 0}`);

        // 1. Improved Message Role Mapping - Keep more history for proper context
        const openAIMessages = messages
            .map((msg: any, index: number) => {
             let role = 'user'; // Default fallback
             let content = msg.content;

                // More precise role mapping
             if (msg.role === 'system') {
                 role = 'system';
             } else if (msg.role === 'assistant') {
                 role = 'assistant';
             } else if (msg.role === 'user') {
                 role = 'user';
             } else if (msg.type === 'TextMessage') {
                    // TextMessage can be from user or assistant
                    role = msg.role === 'assistant' ? 'assistant' : 'user';
             } else if (msg.type === 'ActionExecutionMessage') {
                    // Action execution is from assistant, but we'll skip it
                    // to avoid tool call complexity
                    console.log(`[SiliconFlowAdapter] Skipping ActionExecutionMessage at index ${index}`);
                    return null;
             } else if (msg.type === 'ResultMessage') {
                    // Result messages need tool_call_id, so we skip them
                    console.log(`[SiliconFlowAdapter] Skipping ResultMessage at index ${index}`);
                    return null;
             }

                // Validate role
                const validRoles = ['system', 'assistant', 'user'];
             if (!validRoles.includes(role)) {
                    console.warn(`[SiliconFlowAdapter] Invalid role: ${role} at index ${index}, falling back to user`);
                 role = 'user';
             }
             
             // Ensure content is string
             if (typeof content !== 'string') {
                 content = JSON.stringify(content || "");
             }
                
                // Skip empty messages
                if (!content || content.trim() === '' || content === '{}' || content === 'null') {
                    console.log(`[SiliconFlowAdapter] Skipping empty message at index ${index}`);
                    return null;
             }

             return { role, content };
            })
            .filter((msg: any) => msg !== null); // Remove null entries

        console.log(`[SiliconFlowAdapter] Processed ${openAIMessages.length} messages from ${messages.length} original messages`);

        // Inject or prepend System Prompt
        // Check if the first message is system, if so, append/replace. If not, prepend.
        if (openAIMessages.length > 0 && openAIMessages[0].role === 'system') {
            openAIMessages[0].content = `${SYSTEM_PROMPT}\n\n${openAIMessages[0].content}`;
        } else {
            openAIMessages.unshift({ role: 'system', content: SYSTEM_PROMPT });
        }

        // Helper to convert CopilotKit actions to OpenAI tools
        // Due to CopilotKit parameter serialization issues, we hardcode known action schemas
        const KNOWN_ACTION_SCHEMAS: Record<string, any> = {
            navigateToPage: {
                type: "object",
                properties: {
                    page: {
                        type: "string",
                        description: "The target page view. Options: dashboard, monitor, alert, patrol, broadcast. Also accepts Chinese: ç»¼åˆæ€åŠ¿/ç›‘æ§ä¸­å¿ƒ/é¢„è­¦ä¸­å¿ƒ/å·¡æŸ¥æ²»ç†/å¹¿æ’­å–Šè¯"
                    }
                },
                required: ["page"]
            },
            setDashboardMode: {
                type: "object",
                properties: {
                    mode: {
                        type: "string",
                        description: "The dashboard center panel mode. Options: video-grid (ç›‘æ§å¢™), map (åœ°å›¾), ai-chat (AIåŠ©æ‰‹)"
                    }
                },
                required: ["mode"]
            },
            setEmergencyMode: {
                type: "object",
                properties: {
                    active: {
                        type: "boolean",
                        description: "True to activate emergency mode, false to deactivate"
                    }
                },
                required: ["active"]
            },
            toggleSidebar: {
                type: "object",
                properties: {},
                description: "Toggle the navigation sidebar. No parameters needed."
            },
            configurePatrol: {
                type: "object",
                properties: {
                    active: {
                        type: "boolean",
                        description: "Start or stop automated camera patrolling"
                    },
                    interval: {
                        type: "number",
                        description: "Time interval between camera switches in minutes"
                    }
                }
            },
            generateChart: {
                type: "object",
                properties: {
                    dataSource: {
                        type: "string",
                        description: "æ•°æ®æºAPIç«¯ç‚¹ã€‚å¯é€‰å€¼ï¼š/api/stats/camerasï¼ˆæ‘„åƒå¤´ç»Ÿè®¡ï¼‰ã€/api/stats/alertsï¼ˆå‘Šè­¦ç»Ÿè®¡ï¼‰ã€/api/stats/patrolï¼ˆå·¡é€»ç»Ÿè®¡ï¼‰ã€/api/stats/systemï¼ˆç³»ç»Ÿæ€§èƒ½ï¼‰",
                        enum: ["/api/stats/cameras", "/api/stats/alerts", "/api/stats/patrol", "/api/stats/system"]
                    },
                    chartType: {
                        type: "string",
                        description: "å›¾è¡¨ç±»å‹ã€‚line=æŠ˜çº¿å›¾ï¼ˆè¶‹åŠ¿åˆ†æï¼‰ã€bar=æŸ±çŠ¶å›¾ï¼ˆæ•°é‡å¯¹æ¯”ï¼‰ã€pie=é¥¼å›¾ï¼ˆå æ¯”åˆ†å¸ƒï¼‰ã€scatter=æ•£ç‚¹å›¾ï¼ˆç›¸å…³æ€§åˆ†æï¼‰ã€radar=é›·è¾¾å›¾ï¼ˆå¤šç»´è¯„ä¼°ï¼‰",
                        enum: ["line", "bar", "pie", "scatter", "radar"]
                    },
                    title: {
                        type: "string",
                        description: "å›¾è¡¨æ ‡é¢˜ï¼ˆä¸­æ–‡ï¼‰ï¼Œå¦‚'æœ€è¿‘7å¤©å‘Šè­¦è¶‹åŠ¿'ã€'å‘Šè­¦çº§åˆ«åˆ†å¸ƒ'"
                    },
                    description: {
                        type: "string",
                        description: "å›¾è¡¨æè¿°è¯´æ˜ï¼ˆå¯é€‰ï¼‰ï¼Œç®€è¦è¯´æ˜å›¾è¡¨å±•ç¤ºçš„å†…å®¹"
                    },
                    timeRange: {
                        type: "string",
                        description: "æ—¶é—´èŒƒå›´ã€‚1d=æœ€è¿‘1å¤©/24å°æ—¶ï¼Œ7d=æœ€è¿‘7å¤©/ä¸€å‘¨ï¼ˆé»˜è®¤ï¼‰ï¼Œ30d=æœ€è¿‘30å¤©/ä¸€æœˆï¼Œ90d=æœ€è¿‘90å¤©/ä¸‰æœˆ",
                        enum: ["1d", "7d", "30d", "90d"]
                    },
                    dataMapping: {
                        type: "object",
                        description: "æ•°æ®æ˜ å°„é…ç½®ï¼ˆå¯é€‰ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹ï¼‰ã€‚ç”¨äºæŒ‡å®šå¦‚ä½•ä»APIæ•°æ®ä¸­æå–å›¾è¡¨æ‰€éœ€å­—æ®µã€‚æŠ˜çº¿å›¾/æŸ±çŠ¶å›¾ç¤ºä¾‹ï¼š{xAxis: 'trend.categories', series: 'trend.series'}ã€‚é¥¼å›¾ç¤ºä¾‹ï¼š{data: 'levelDistribution'} æˆ– {data: 'typeDistribution'}ã€‚å¦‚æœä¸æä¾›ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹æ•°æ®å­—æ®µã€‚",
                        additionalProperties: true
                    }
                },
                required: ["dataSource", "chartType", "title"]
            }
        };
        
        // Schema for generateInsight action
        KNOWN_ACTION_SCHEMAS["generateInsight"] = {
            type: "object",
            properties: {
                title: {
                    type: "string",
                    description: "æ ‡é¢˜ï¼šåˆ†ææ€»ç»“çš„æ ‡é¢˜ï¼Œå¦‚'å‘Šè­¦æ€åŠ¿åˆ†æ'ã€'æ•°æ®åˆ†ææŠ¥å‘Š'"
                },
                content: {
                    type: "string",
                    description: "å†…å®¹ï¼šMarkdownæ ¼å¼çš„åˆ†ææ€»ç»“å†…å®¹ã€‚åº”åŒ…å«æ•°æ®æ‘˜è¦ã€è¶‹åŠ¿åˆ†æã€å»ºè®®æªæ–½ã€é£é™©è¯„ä¼°ç­‰éƒ¨åˆ†ã€‚ä½¿ç”¨#æ ‡é¢˜ã€**åŠ ç²—**ã€åˆ—è¡¨ç­‰Markdownè¯­æ³•ã€‚"
                },
                contentType: {
                    type: "string",
                    description: "å†…å®¹ç±»å‹ï¼šmarkdownï¼ˆæ¨èï¼Œæ”¯æŒæ ¼å¼åŒ–ï¼‰, textï¼ˆçº¯æ–‡æœ¬ï¼‰, htmlï¼ˆHTMLæ ¼å¼ï¼‰",
                    enum: ["markdown", "text", "html"]
                },
                layout: {
                    type: "string",
                    description: "å¸ƒå±€ï¼šhalfï¼ˆå åŠè¡Œï¼Œä¸å›¾è¡¨å¹¶æ’æ˜¾ç¤ºï¼Œæ¨èï¼‰, fullï¼ˆå æ»¡ä¸€è¡Œï¼‰",
                    enum: ["half", "full"]
                }
            },
            required: ["title", "content"]
        };

        const tools = actions && actions.length > 0 ? actions.map((action: any) => {
            // Use hardcoded schema if available, otherwise use flexible schema
            const parametersSchema = KNOWN_ACTION_SCHEMAS[action.name] || {
                type: "object",
                properties: {},
                additionalProperties: true,
                description: `Parameters for ${action.name}. The model should infer appropriate parameters from the context.`
            };
            
            console.log(`[SiliconFlowAdapter] Using schema for ${action.name}:`, JSON.stringify(parametersSchema, null, 2));
            
            return {
            type: "function",
            function: {
                name: action.name,
                description: action.description,
                    parameters: parametersSchema,
            }
            };
        }) : undefined;

        // Manually handle the stream events
        eventSource.stream(async (eventStream$: any) => {
            let startedTextMessage = false;
            let messageId: string | undefined;
            const toolCallMap = new Map<number, string>(); // index -> id
            const calledToolNames: string[] = []; // Track which tools were called
            const fullMessageBuffer: string[] = []; // ç´¯ç§¯å®Œæ•´æ¶ˆæ¯å†…å®¹
            
            // å®æ—¶TTSå˜é‡
            const sessionId = `session_${Date.now()}_${Math.random().toString(36).substring(7)}`;
            let ttsBuffer = ''; // ç´¯ç§¯å¾…TTSçš„æ–‡æœ¬
            let ttsIndex = 0; // TTSç‰‡æ®µç´¢å¼•
            const TTS_THRESHOLD = 50; // ç´¯ç§¯50å­—ç¬¦å°±å‘é€TTSï¼ˆæé«˜é˜ˆå€¼ï¼Œå‡å°‘åˆ‡åˆ†ï¼‰
            
            // æ¸…ç†Markdownæ ¼å¼å¹¶ä¼˜åŒ–æ–‡æœ¬ä»¥é€‚åˆTTSçš„å‡½æ•°
            // ä¿ç•™æ‰€æœ‰æ­£å¸¸æ ‡ç‚¹ç¬¦å·ï¼ˆé€—å·ã€å¥å·ã€æ„Ÿå¹å·ã€é—®å·ã€åˆ†å·ï¼‰ï¼Œåªåˆ é™¤Markdownæ ¼å¼ç¬¦å·
            const cleanTextForTTS = (text: string): string => {
                let cleaned = text;
                
                // ç§»é™¤Markdownæ ¼å¼ç¬¦å·ï¼ˆä¿ç•™å†…å®¹ï¼‰
                cleaned = cleaned.replace(/(\*\*|__)(.*?)\1/g, '$2'); // ç§»é™¤ç²—ä½“/æ–œä½“æ ‡è®°ï¼Œä¿ç•™æ–‡æœ¬
                cleaned = cleaned.replace(/(\*|_)(.*?)\1/g, '$2'); // ç§»é™¤æ–œä½“æ ‡è®°ï¼Œä¿ç•™æ–‡æœ¬
                cleaned = cleaned.replace(/^#+\s/gm, ''); // ç§»é™¤æ ‡é¢˜æ ‡è®°
                cleaned = cleaned.replace(/^[-*+]\s/gm, ''); // ç§»é™¤åˆ—è¡¨æ ‡è®°ï¼ˆ- * +ï¼‰
                cleaned = cleaned.replace(/^\d+\.\s/gm, ''); // ç§»é™¤æœ‰åºåˆ—è¡¨æ•°å­—
                cleaned = cleaned.replace(/\[(.*?)\]\(.*?\)/g, '$1'); // ç§»é™¤é“¾æ¥æ ¼å¼ï¼Œä¿ç•™æ–‡æœ¬
                cleaned = cleaned.replace(/`{1,3}([^`]+)`{1,3}/g, '$1'); // ç§»é™¤ä»£ç æ ‡è®°ï¼Œä¿ç•™å†…å®¹
                cleaned = cleaned.replace(/^>\s/gm, ''); // ç§»é™¤å¼•ç”¨æ ‡è®°
                cleaned = cleaned.replace(/<[^>]+>/g, ''); // ç§»é™¤HTMLæ ‡ç­¾
                
                // å¤„ç†æ¢è¡Œç¬¦ï¼šå¦‚æœæ¢è¡Œå‰æ²¡æœ‰æ ‡ç‚¹ç¬¦å·ï¼Œæ·»åŠ å¥å·
                cleaned = cleaned.replace(/([^ï¼Œã€‚ï¼ï¼Ÿï¼›\n])\n+/g, '$1ã€‚');
                // å¤šä¸ªè¿ç»­æ¢è¡Œç¬¦æ›¿æ¢ä¸ºå•ä¸ªå¥å·
                cleaned = cleaned.replace(/\n{2,}/g, 'ã€‚');
                // å•ä¸ªæ¢è¡Œç¬¦æ›¿æ¢ä¸ºç©ºæ ¼
                cleaned = cleaned.replace(/\n/g, ' ');
                
                // ç¡®ä¿æ ‡ç‚¹ç¬¦å·åæœ‰é€‚å½“çš„ç©ºæ ¼
                cleaned = cleaned.replace(/([ï¼Œã€‚ï¼ï¼Ÿï¼›])([^ï¼Œã€‚ï¼ï¼Ÿï¼›\s])/g, '$1 $2');
                
                // ç§»é™¤å¤šä½™çš„ç©ºæ ¼ï¼Œä½†ä¿ç•™æ ‡ç‚¹ç¬¦å·åçš„ç©ºæ ¼
                cleaned = cleaned.replace(/[ \t]+/g, ' ');
                
                return cleaned.trim();
            };
            
            // æŒ‰å¥å­è¾¹ç•Œåˆ‡åˆ†æ–‡æœ¬çš„å‡½æ•°ï¼ˆä¿ç•™æ‰€æœ‰æ ‡ç‚¹ç¬¦å·ï¼‰
            const splitTextBySentences = (text: string, maxLength: number): string[] => {
                const sentences: string[] = [];
                const sentenceEndings = /[ã€‚ï¼ï¼Ÿ]/; // å¥å­ç»“æŸç¬¦
                
                // å¦‚æœæ–‡æœ¬é•¿åº¦å°äºé˜ˆå€¼ï¼Œç›´æ¥è¿”å›
                if (text.length <= maxLength) {
                    return [text];
                }
                
                let currentChunk = '';
                
                for (let i = 0; i < text.length; i++) {
                    currentChunk += text[i];
                    
                    // å¦‚æœé‡åˆ°å¥å­ç»“æŸç¬¦ï¼ˆå¥å·ã€é—®å·ã€æ„Ÿå¹å·ï¼‰
                    if (sentenceEndings.test(text[i])) {
                        // å¦‚æœå½“å‰å—å·²ç»è¾¾åˆ°é˜ˆå€¼ï¼Œåˆ‡åˆ†
                        if (currentChunk.length >= maxLength) {
                            sentences.push(currentChunk.trim());
                            currentChunk = '';
                        }
                    }
                    // å¦‚æœå½“å‰å—è¶…è¿‡é˜ˆå€¼ä¸”æ²¡æœ‰æ‰¾åˆ°å¥å­è¾¹ç•Œï¼Œåœ¨é€—å·æˆ–åˆ†å·å¤„åˆ‡åˆ†
                    else if (currentChunk.length >= maxLength * 1.5) {
                        const lastComma = currentChunk.lastIndexOf('ï¼Œ');
                        const lastSemicolon = currentChunk.lastIndexOf('ï¼›');
                        const lastPause = Math.max(lastComma, lastSemicolon);
                        
                        if (lastPause > maxLength * 0.5) {
                            sentences.push(currentChunk.substring(0, lastPause + 1).trim());
                            currentChunk = currentChunk.substring(lastPause + 1);
                        } else {
                            // å¦‚æœæ‰¾ä¸åˆ°åˆé€‚çš„åˆ‡åˆ†ç‚¹ï¼Œå¼ºåˆ¶åœ¨é˜ˆå€¼å¤„åˆ‡åˆ†
                            sentences.push(currentChunk.substring(0, maxLength).trim());
                            currentChunk = currentChunk.substring(maxLength);
                        }
                    }
                }
                
                // æ·»åŠ å‰©ä½™å†…å®¹
                if (currentChunk.trim().length > 0) {
                    sentences.push(currentChunk.trim());
                }
                
                return sentences.filter(s => s.length > 0);
            };
            
            // å‘é€TTSåˆ°å‰ç«¯çš„å‡½æ•°
            const sendTTSChunk = async (text: string) => {
                if (!text || text.trim().length === 0) return;
                
                const cleanedText = cleanTextForTTS(text);
                if (!cleanedText) return;
                
                console.log(`[Real-time TTS] Sending chunk ${ttsIndex}: "${cleanedText.substring(0, 50)}..." (${cleanedText.length} chars)`);
                
                try {
                    // è°ƒç”¨TTS API
                    const ttsResponse = await fetch('https://api.siliconflow.cn/v1/audio/speech', {
                        method: 'POST',
                        headers: {
                            'Authorization': `Bearer ${SILICONFLOW_API_KEY}`,
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({
                            model: 'FunAudioLLM/CosyVoice2-0.5B',
                            input: cleanedText,
                            voice: 'FunAudioLLM/CosyVoice2-0.5B:diana',
                            response_format: 'mp3',
                            sample_rate: 32000,
                            stream: false,
                            speed: 1.0,
                            gain: 0
                        })
                    });
                    
                    if (ttsResponse.ok) {
                        const audioBuffer = Buffer.from(await ttsResponse.arrayBuffer());
                        console.log(`[Real-time TTS] Generated audio for chunk ${ttsIndex}: ${audioBuffer.length} bytes`);
                        
                        const audioData = {
                            sessionId,
                            audio: audioBuffer,
                            text: cleanedText,
                            index: ttsIndex
                        };
                        
                        // æ£€æŸ¥æ˜¯å¦æœ‰SSEè¿æ¥
                        if (sseConnections.has(sessionId)) {
                            // ç›´æ¥é€šè¿‡äº‹ä»¶å‘å°„å™¨æ¨é€
                            console.log(`[Real-time TTS] SSE connected, sending immediately`);
                            audioEventEmitter.emit('audio', audioData);
                        } else {
                            // ç¼“å†²éŸ³é¢‘ï¼Œç­‰å¾…SSEè¿æ¥
                            console.log(`[Real-time TTS] No SSE connection yet, buffering chunk ${ttsIndex}`);
                            if (!audioBuffers.has(sessionId)) {
                                audioBuffers.set(sessionId, []);
                            }
                            audioBuffers.get(sessionId)!.push(audioData);
                        }
                        
                        ttsIndex++;
                    } else {
                        console.error(`[Real-time TTS] TTS failed:`, ttsResponse.status);
                    }
                } catch (err) {
                    console.error(`[Real-time TTS] Error:`, err);
                }
            };

            try {
                console.log("[SiliconFlowAdapter] Requesting streaming completion from SiliconFlow (DeepSeek-V3.2-Exp)...");

                const payload = {
                    model: "deepseek-ai/DeepSeek-V3.2-Exp",
                    messages: openAIMessages,
                    tools: tools,
                    stream: true,
                    stream_options: { include_usage: true }
                };
                
                // Log payload summary
                console.log("[SiliconFlowAdapter] Request summary:");
                console.log("  - Messages count:", openAIMessages.length);
                console.log("  - Tools count:", tools?.length || 0);
                if (tools && tools.length > 0) {
                    console.log("  - Tool names:", tools.map((t: any) => t.function.name).join(", "));
                }

                const stream = await openai.chat.completions.create(payload as any) as unknown as AsyncIterable<any>;
                
                for await (const chunk of stream) {
                    if (!chunk.choices || chunk.choices.length === 0) {
                        continue;
                    }

                    const delta = chunk.choices[0].delta;
                    if (!delta) continue;

                    // Handle content streaming (DeepSeek-V3.2-Exp)
                    const content = delta.content || "";
                    
                    if (content) {
                        // ç´¯ç§¯å†…å®¹åˆ°ç¼“å†²åŒº
                        fullMessageBuffer.push(content);
                        
                        if (!startedTextMessage) {
                            messageId = chunk.id || `msg_${Date.now()}`; 
                            eventStream$.sendTextMessageStart({ messageId });
                            startedTextMessage = true;
                            
                            // ç«‹å³å‘é€sessionIdç»™å‰ç«¯ï¼ˆä½œä¸ºç¬¬ä¸€ä¸ªå†…å®¹ï¼‰
                            eventStream$.sendTextMessageContent({
                                messageId: messageId!,
                                content: `<!--AUDIO_SESSION:${sessionId}-->`
                            });
                            
                            console.log(`[Real-time TTS] Sent session ID to frontend: ${sessionId}`);
                        }
                        
                        // å‘é€å®é™…å†…å®¹
                        eventStream$.sendTextMessageContent({
                            messageId: messageId!,
                            content: content
                        });
                        
                        // ç´¯ç§¯åˆ°TTSç¼“å†²åŒº
                        ttsBuffer += content;
                        
                        // å½“ç´¯ç§¯è¶³å¤Ÿé•¿åº¦ï¼ŒæŒ‰å¥å­è¾¹ç•Œåˆ‡åˆ†å¹¶å‘é€TTS
                        if (ttsBuffer.length >= TTS_THRESHOLD) {
                            const chunks = splitTextBySentences(ttsBuffer, TTS_THRESHOLD);
                            
                            // å‘é€æ‰€æœ‰å®Œæ•´çš„å¥å­å—ï¼ˆé™¤äº†æœ€åä¸€ä¸ªï¼‰
                            for (let i = 0; i < chunks.length - 1; i++) {
                                await sendTTSChunk(chunks[i]);
                            }
                            
                            // ä¿ç•™æœ€åä¸€ä¸ªå—ï¼ˆå¯èƒ½ä¸å®Œæ•´ï¼‰
                            ttsBuffer = chunks.length > 0 ? chunks[chunks.length - 1] : '';
                        }
                    }

                    // Handle tool calls
                    if (delta.tool_calls) {
                        for (const toolCall of delta.tool_calls) {
                            const index = toolCall.index;
                            
                            if (toolCall.id) {
                                // New tool call start
                                const id = toolCall.id;
                                const toolName = toolCall.function?.name || "";
                                toolCallMap.set(index, id);
                                
                                console.log(`[Tool Call] Starting: ${toolName} (id: ${id}, index: ${index})`);
                                
                                // Track tool name for intelligent fallback
                                if (toolName && !calledToolNames.includes(toolName)) {
                                    calledToolNames.push(toolName);
                                }
                                
                                console.log(`[Tool Call] Sending ActionExecutionStart to frontend...`);
                                eventStream$.sendActionExecutionStart({
                                    actionExecutionId: id,
                                    actionName: toolName,
                                    parentMessageId: chunk.id || messageId || `msg_${Date.now()}`
                                });
                            }

                            const args = toolCall.function?.arguments;
                            if (args && toolCallMap.has(index)) {
                                console.log(`[Tool Call] Sending arguments for tool ${toolCallMap.get(index)}: ${args.substring(0, 100)}...`);
                                eventStream$.sendActionExecutionArgs({
                                    actionExecutionId: toolCallMap.get(index)!,
                                    args: args
                                });
                            }
                        }
                    }
                }
                
                // å‘é€å‰©ä½™çš„TTSå†…å®¹
                if (ttsBuffer.trim().length > 0) {
                    console.log(`[Real-time TTS] Sending final chunk: "${ttsBuffer.substring(0, 50)}..." (${ttsBuffer.length} chars)`);
                    await sendTTSChunk(ttsBuffer);
                    ttsBuffer = '';
                }
                
                // å‘é€TTSå®Œæˆäº‹ä»¶
                audioEventEmitter.emit('complete', { sessionId });
                console.log(`[Real-time TTS] All chunks sent for session ${sessionId}`);
                
                // Generate intelligent fallback response based on tool calls
                // This ensures CopilotKit doesn't auto-retry while providing meaningful feedback
                if (toolCallMap.size > 0 && !startedTextMessage) {
                    console.log("[SiliconFlowAdapter] Model called tools without text response, generating intelligent fallback");
                    
                    // Generate contextual response based on the tools that were called
                    let fallbackMessage = "æ“ä½œå·²æ‰§è¡Œ";
                    
                    if (calledToolNames.length > 0) {
                        // Map tool names to user-friendly Chinese messages
                        const actionMap: Record<string, string> = {
                            'navigateToPage': 'é¡µé¢åˆ‡æ¢æˆåŠŸ',
                            'setDashboardMode': 'è§†å›¾æ¨¡å¼å·²åˆ‡æ¢',
                            'setEmergencyMode': 'ç´§æ€¥æ¨¡å¼çŠ¶æ€å·²æ›´æ–°',
                            'configurePatrol': 'å·¡é€»é…ç½®å·²è°ƒæ•´',
                            'toggleSidebar': 'ä¾§è¾¹æ æ˜¾ç¤ºå·²åˆ‡æ¢',
                            'generateChart': 'å›¾è¡¨ç”Ÿæˆä¸­'
                        };
                        
                        const firstTool = calledToolNames[0];
                        fallbackMessage = actionMap[firstTool] || 'æ“ä½œå·²å®Œæˆ';
                        
                        // If multiple tools were called, indicate that
                        if (calledToolNames.length > 1) {
                            fallbackMessage += `ï¼Œå…±æ‰§è¡Œäº†${calledToolNames.length}ä¸ªæ“ä½œ`;
                        }
                    }
                    
                    messageId = `msg_${Date.now()}`;
                    // å°†fallbackæ¶ˆæ¯æ·»åŠ åˆ°ç¼“å†²åŒºï¼Œä»¥ä¾¿æ—¥å¿—æ­£ç¡®æ˜¾ç¤º
                    fullMessageBuffer.push(fallbackMessage);
                    
                    eventStream$.sendTextMessageStart({ messageId });
                    eventStream$.sendTextMessageContent({
                        messageId,
                        content: fallbackMessage
                    });
                    eventStream$.sendTextMessageEnd({ messageId });
                    console.log(`[SiliconFlowAdapter] Sent intelligent fallback: "${fallbackMessage}" for tools: [${calledToolNames.join(', ')}]`);
                }
                
                // End text message if started
                if (startedTextMessage && messageId) {
                    eventStream$.sendTextMessageEnd({ messageId });
                }

                // End all tool calls
                for (const id of toolCallMap.values()) {
                    eventStream$.sendActionExecutionEnd({ actionExecutionId: id });
                }
                
                // æ‰“å°å®Œæ•´çš„AIå›å¤å†…å®¹
                const fullMessage = fullMessageBuffer.join('');
                console.log("[SiliconFlowAdapter] ===== AI Complete Response =====");
                console.log(`[SiliconFlowAdapter] Total length: ${fullMessage.length} chars`);
                console.log(`[SiliconFlowAdapter] Content: "${fullMessage}"`);
                console.log("[SiliconFlowAdapter] ================================");
                
                console.log("[SiliconFlowAdapter] Stream completed successfully.");
                eventStream$.complete();

            } catch (err: any) {
                console.error("[SiliconFlowAdapter] API Error:", err);
                
                // Handle common errors...
                if (err.status === 429) {
                     const msg = "SiliconFlow rate limit exceeded. Please try again later.";
                     if (!startedTextMessage) { 
                     eventStream$.sendTextMessageStart({ messageId: "error" });
                     eventStream$.sendTextMessageContent({ messageId: "error", content: msg });
                     eventStream$.sendTextMessageEnd({ messageId: "error" });
                     } else {
                         eventStream$.sendTextMessageContent({ messageId: messageId || "error", content: `\n\n[Error: ${msg}]` });
                         if (messageId) eventStream$.sendTextMessageEnd({ messageId });
                     }
                     eventStream$.complete();
                     return;
                }
                
                 if (err.status === 400) {
                     const msg = "Model API Error (400): Invalid request.";
                     if (!startedTextMessage) {
                         eventStream$.sendTextMessageStart({ messageId: "error" });
                         eventStream$.sendTextMessageContent({ messageId: "error", content: msg });
                         eventStream$.sendTextMessageEnd({ messageId: "error" });
                     }
                     eventStream$.complete();
                     return;
                }

                if (!startedTextMessage) {
                     try {
                        eventStream$.sendTextMessageStart({ messageId: "error" });
                        eventStream$.sendTextMessageContent({ messageId: "error", content: `Error: ${err.message || "Unknown error"}` });
                        eventStream$.sendTextMessageEnd({ messageId: "error" });
                     } catch (e) {
                        console.error("Failed to send error to stream", e);
                     }
                }

                eventStream$.error(err);
            }
        });

        return {
            threadId: request.threadId || "default_thread"
        };
    }
}

const serviceAdapter = new SiliconFlowAdapter();

// ==================== å®æ—¶éŸ³é¢‘æ¨é€ SSE ====================
// GET /api/audio-stream/:sessionId
// å‰ç«¯é€šè¿‡SSEè¿æ¥æ¥æ”¶å®æ—¶ç”Ÿæˆçš„TTSéŸ³é¢‘
app.get('/api/audio-stream/:sessionId', (req, res) => {
  const { sessionId } = req.params;
  
  console.log(`[Audio SSE] Client connected: ${sessionId}`);

  // è®¾ç½®SSEå“åº”å¤´
  res.setHeader('Content-Type', 'text/event-stream');
  res.setHeader('Cache-Control', 'no-cache');
  res.setHeader('Connection', 'keep-alive');
  res.setHeader('X-Accel-Buffering', 'no');

  // æ ‡è®°æ­¤sessionå·²æœ‰SSEè¿æ¥
  sseConnections.add(sessionId);

  // å‘é€ç¼“å†²çš„éŸ³é¢‘ï¼ˆå¦‚æœæœ‰ï¼‰
  const bufferedAudio = audioBuffers.get(sessionId);
  if (bufferedAudio && bufferedAudio.length > 0) {
    console.log(`[Audio SSE] Sending ${bufferedAudio.length} buffered audio chunks`);
    for (const chunk of bufferedAudio) {
      const audioBase64 = chunk.audio.toString('base64');
      res.write(`data: ${JSON.stringify({
        type: 'audio',
        audio: audioBase64,
        text: chunk.text,
        index: chunk.index
      })}\n\n`);
    }
    // æ¸…ç©ºç¼“å†²
    audioBuffers.delete(sessionId);
  }

  // å¿ƒè·³ï¼Œé˜²æ­¢è¿æ¥è¶…æ—¶
  const heartbeat = setInterval(() => {
    res.write(': heartbeat\n\n');
  }, 30000);

  // ç›‘å¬éŸ³é¢‘äº‹ä»¶
  const audioHandler = (data: { sessionId: string; audio: Buffer; text: string; index: number }) => {
    if (data.sessionId === sessionId) {
      const audioBase64 = data.audio.toString('base64');
      res.write(`data: ${JSON.stringify({
        type: 'audio',
        audio: audioBase64,
        text: data.text,
        index: data.index
      })}\n\n`);
      console.log(`[Audio SSE] Sent audio chunk ${data.index} to ${sessionId} (${data.audio.length} bytes)`);
    }
  };

  const completeHandler = (data: { sessionId: string }) => {
    if (data.sessionId === sessionId) {
      res.write(`data: ${JSON.stringify({ type: 'complete' })}\n\n`);
      console.log(`[Audio SSE] Sent complete event to ${sessionId}`);
    }
  };

  audioEventEmitter.on('audio', audioHandler);
  audioEventEmitter.on('complete', completeHandler);

  // å®¢æˆ·ç«¯æ–­å¼€è¿æ¥
  req.on('close', () => {
    console.log(`[Audio SSE] Client disconnected: ${sessionId}`);
    clearInterval(heartbeat);
    sseConnections.delete(sessionId);
    audioBuffers.delete(sessionId); // æ¸…ç†ç¼“å†²
    audioEventEmitter.off('audio', audioHandler);
    audioEventEmitter.off('complete', completeHandler);
  });
});

// ==================== è¯­éŸ³è¯†åˆ« API ====================
// POST /api/speech-to-text
// ä½¿ç”¨ FunAudioLLM/SenseVoiceSmall æ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«
app.post('/api/speech-to-text', upload.single('audio'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'No audio file provided' });
    }

    console.log('[ASR] Received audio file:', {
      originalname: req.file.originalname,
      mimetype: req.file.mimetype,
      size: req.file.size,
      bufferLength: req.file.buffer.length
    });

    // éªŒè¯éŸ³é¢‘æ•°æ®
    if (req.file.buffer.length === 0) {
      return res.status(400).json({ error: 'Audio file is empty' });
    }

    // ä½¿ç”¨axioså’Œform-dataå‘é€è¯·æ±‚
    const FormData = (await import('form-data')).default;
    const formData = new FormData();
    
    // å°†Bufferä½œä¸ºstreamæ·»åŠ åˆ°formData
    formData.append('file', req.file.buffer, {
      filename: 'recording.webm',
      contentType: 'audio/webm'
    });
    formData.append('model', 'FunAudioLLM/SenseVoiceSmall');

    console.log('[ASR] Sending request to SiliconFlow API with axios...');

    try {
      // ä½¿ç”¨axioså‘é€è¯·æ±‚ï¼ˆaxioså¯¹form-dataæ”¯æŒæ›´å¥½ï¼‰
      const response = await axios.post(
        'https://api.siliconflow.cn/v1/audio/transcriptions',
        formData,
        {
          headers: {
            'Authorization': `Bearer ${SILICONFLOW_API_KEY}`,
            ...formData.getHeaders()
          },
          maxBodyLength: Infinity,
          maxContentLength: Infinity
        }
      );

      console.log('[ASR] Recognition successful:', response.data);

      res.json({ 
        text: response.data.text || '',
        language: response.data.language || 'zh'
      });

    } catch (error: unknown) {
      if (axios.isAxiosError(error) && error.response) {
        console.error('[ASR] API Error:', error.response.status, error.response.data);
        return res.status(error.response.status).json({ 
          error: 'Speech recognition failed', 
          details: error.response.data
        });
      }
      throw error;
    }

  } catch (error: unknown) {
    const err = error as Error;
    console.error('[ASR] Error:', err);
    res.status(500).json({ 
      error: 'Speech recognition failed', 
      message: err.message 
    });
  }
});

// ==================== å®Œæ•´AIè¯­éŸ³åˆæˆ API ====================
// POST /api/complete-ai-speech
// æ¥æ”¶AIçš„å®Œæ•´å›å¤ï¼Œä¸€æ¬¡æ€§åˆæˆå®Œæ•´è¯­éŸ³ï¼ˆä¸åˆ‡åˆ†ï¼‰
app.post('/api/complete-ai-speech', async (req, res) => {
  try {
    const { text } = req.body;

    if (!text || typeof text !== 'string') {
      return res.status(400).json({ error: 'No text provided' });
    }

    console.log('[Complete AI TTS] Starting TTS for text length:', text.length);
    console.log('[Complete AI TTS] Full text:', text);

    // æ¸…ç†æ–‡æœ¬ä¸­çš„Markdownæ ¼å¼å¹¶ä¼˜åŒ–TTSæ–­å¥
    // ä¿ç•™æ‰€æœ‰æ­£å¸¸æ ‡ç‚¹ç¬¦å·ï¼ˆé€—å·ã€å¥å·ã€æ„Ÿå¹å·ã€é—®å·ã€åˆ†å·ï¼‰ï¼Œåªåˆ é™¤Markdownæ ¼å¼ç¬¦å·
    const cleanText = (input: string): string => {
      let cleaned = input;
      
      // ç§»é™¤Markdownæ ¼å¼ç¬¦å·ï¼ˆä¿ç•™å†…å®¹ï¼‰
      cleaned = cleaned.replace(/(\*\*|__)(.*?)\1/g, '$2'); // ç§»é™¤ç²—ä½“/æ–œä½“æ ‡è®°ï¼Œä¿ç•™æ–‡æœ¬
      cleaned = cleaned.replace(/(\*|_)(.*?)\1/g, '$2'); // ç§»é™¤æ–œä½“æ ‡è®°ï¼Œä¿ç•™æ–‡æœ¬
      cleaned = cleaned.replace(/^#+\s/gm, ''); // ç§»é™¤æ ‡é¢˜æ ‡è®°
      cleaned = cleaned.replace(/^[-*+]\s/gm, ''); // ç§»é™¤åˆ—è¡¨æ ‡è®°ï¼ˆ- * +ï¼‰
      cleaned = cleaned.replace(/^\d+\.\s/gm, ''); // ç§»é™¤æœ‰åºåˆ—è¡¨æ•°å­—
      cleaned = cleaned.replace(/\[(.*?)\]\(.*?\)/g, '$1'); // ç§»é™¤é“¾æ¥æ ¼å¼ï¼Œä¿ç•™æ–‡æœ¬
      cleaned = cleaned.replace(/`{1,3}([^`]+)`{1,3}/g, '$1'); // ç§»é™¤ä»£ç æ ‡è®°ï¼Œä¿ç•™å†…å®¹
      cleaned = cleaned.replace(/^>\s/gm, ''); // ç§»é™¤å¼•ç”¨æ ‡è®°
      cleaned = cleaned.replace(/<[^>]+>/g, ''); // ç§»é™¤HTMLæ ‡ç­¾
      
      // å¤„ç†æ¢è¡Œç¬¦ï¼šå¦‚æœæ¢è¡Œå‰æ²¡æœ‰æ ‡ç‚¹ç¬¦å·ï¼Œæ·»åŠ å¥å·
      cleaned = cleaned.replace(/([^ï¼Œã€‚ï¼ï¼Ÿï¼›\n])\n+/g, '$1ã€‚');
      // å¤šä¸ªè¿ç»­æ¢è¡Œç¬¦æ›¿æ¢ä¸ºå•ä¸ªå¥å·
      cleaned = cleaned.replace(/\n{2,}/g, 'ã€‚');
      // å•ä¸ªæ¢è¡Œç¬¦æ›¿æ¢ä¸ºç©ºæ ¼
      cleaned = cleaned.replace(/\n/g, ' ');
      
      // ç¡®ä¿æ ‡ç‚¹ç¬¦å·åæœ‰é€‚å½“çš„ç©ºæ ¼
      cleaned = cleaned.replace(/([ï¼Œã€‚ï¼ï¼Ÿï¼›])([^ï¼Œã€‚ï¼ï¼Ÿï¼›\s])/g, '$1 $2');
      
      // ç§»é™¤å¤šä½™çš„ç©ºæ ¼ï¼Œä½†ä¿ç•™æ ‡ç‚¹ç¬¦å·åçš„ç©ºæ ¼
      cleaned = cleaned.replace(/[ \t]+/g, ' ');
      
      return cleaned.trim();
    };

    const cleanedText = cleanText(text);
    console.log('[Complete AI TTS] Cleaned text length:', cleanedText.length);
    console.log('[Complete AI TTS] Cleaned text:', cleanedText);

    // ä¸€æ¬¡æ€§è°ƒç”¨TTS APIï¼Œä¸åˆ‡åˆ†
    const ttsResponse = await fetch('https://api.siliconflow.cn/v1/audio/speech', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${SILICONFLOW_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'FunAudioLLM/CosyVoice2-0.5B',
        input: cleanedText,
        voice: 'FunAudioLLM/CosyVoice2-0.5B:diana',
        response_format: 'mp3',
        sample_rate: 32000,
        stream: true, // å¯ç”¨æµå¼è¾“å‡º
        speed: 1.0,
        gain: 0
      })
    });

    if (!ttsResponse.ok) {
      const errorText = await ttsResponse.text();
      console.error('[Complete AI TTS] TTS API Error:', ttsResponse.status, errorText);
      return res.status(ttsResponse.status).json({ 
        error: 'TTS generation failed', 
        details: errorText 
      });
    }

    // æµå¼ä¼ è¾“éŸ³é¢‘åˆ°å‰ç«¯
    res.setHeader('Content-Type', 'audio/mpeg');
    res.setHeader('Transfer-Encoding', 'chunked');

    console.log('[Complete AI TTS] Streaming audio to client...');
    
    // ç›´æ¥ç®¡é“ä¼ è¾“éŸ³é¢‘æµ
    const reader = ttsResponse.body?.getReader();
    if (!reader) {
      throw new Error('No audio stream available');
    }

    let totalBytes = 0;
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      res.write(value);
      totalBytes += value.length;
    }

    console.log(`[Complete AI TTS] Streaming completed, sent ${totalBytes} bytes`);
    res.end();

  } catch (error: unknown) {
    const err = error as Error;
    console.error('[Complete AI TTS] Error:', err);
    if (!res.headersSent) {
      res.status(500).json({ 
        error: 'Complete TTS failed', 
        message: err.message 
      });
    } else {
      res.end();
    }
  }
});

// ==================== è¯­éŸ³åˆæˆ API ====================
// POST /api/text-to-speech
// ä½¿ç”¨ FunAudioLLM/CosyVoice2-0.5B æ¨¡å‹è¿›è¡Œæµå¼è¯­éŸ³åˆæˆ
// æ–‡æ¡£: https://docs.siliconflow.cn/cn/api-reference/audio/create-speech
app.post('/api/text-to-speech', async (req, res) => {
  try {
    const { text } = req.body;

    if (!text || typeof text !== 'string') {
      return res.status(400).json({ error: 'No text provided' });
    }

    console.log('[TTS] Generating speech for text:', text.substring(0, 100));

    // æ ¹æ®ç¡…åŸºæµåŠ¨æ–‡æ¡£ï¼Œè°ƒç”¨TTS API
    const response = await fetch('https://api.siliconflow.cn/v1/audio/speech', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${SILICONFLOW_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'FunAudioLLM/CosyVoice2-0.5B',
        input: text, // ç›´æ¥ä½¿ç”¨æ–‡æœ¬ï¼Œä¸éœ€è¦ç‰¹æ®Šæ ¼å¼ï¼ˆé™¤ééœ€è¦æƒ…æ„Ÿæ§åˆ¶ï¼‰
        voice: 'FunAudioLLM/CosyVoice2-0.5B:diana', // ä½¿ç”¨å®Œæ•´çš„voiceæ ¼å¼
        response_format: 'mp3',
        sample_rate: 32000, // é»˜è®¤32000 Hz
        stream: true, // å¯ç”¨æµå¼è¾“å‡º
        speed: 1.0,
        gain: 0
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('[TTS] API Error:', response.status, errorText);
      
      // å°è¯•è§£æé”™è¯¯å“åº”
      let errorDetails;
      try {
        errorDetails = JSON.parse(errorText);
      } catch {
        errorDetails = { message: errorText };
      }
      
      return res.status(response.status).json({ 
        error: 'Text-to-speech failed', 
        details: errorDetails
      });
    }

    // è®¾ç½®å“åº”å¤´ä¸ºéŸ³é¢‘æµ
    res.setHeader('Content-Type', 'audio/mpeg');
    res.setHeader('Transfer-Encoding', 'chunked');

    // å°†éŸ³é¢‘æµä¼ é€’ç»™å®¢æˆ·ç«¯
    const reader = response.body?.getReader();
    if (reader) {
      const pump = async (): Promise<void> => {
        const { done, value } = await reader.read();
        if (done) {
          res.end();
          return;
        }
        res.write(value);
        return pump();
      };
      await pump();
      console.log('[TTS] Streaming audio completed');
    } else {
      res.status(500).json({ error: 'No response body from TTS API' });
    }

  } catch (error: unknown) {
    const err = error as Error;
    console.error('[TTS] Error:', err);
    if (!res.headersSent) {
      res.status(500).json({ 
        error: 'Text-to-speech failed', 
        message: err.message 
      });
    }
  }
});

// Use the Express adapter provided by the library
app.use('/copilotkit', (req, res, next) => {
  const handler = copilotRuntimeNodeExpressEndpoint({
    endpoint: '/copilotkit',
    runtime: copilotRuntime,
    serviceAdapter,
  });
  
  return handler(req, res, next);
});

app.get('/', (req, res) => {
  res.send('BI Agent Copilot Runtime is running!');
});

app.listen(port, () => {
  console.log(`Copilot Runtime running at http://localhost:${port}`);
});
